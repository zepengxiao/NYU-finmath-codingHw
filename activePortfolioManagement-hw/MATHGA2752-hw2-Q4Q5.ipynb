{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as spop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <br>\n",
    "\n",
    "The program of finding optimal dynamic strategy that $\\displaystyle \\max_{\\theta}\\mathbb{E}[u(W_T^{\\theta})]$ with no trading costs, is implemented below.\n",
    "\n",
    "Something that needs to being specified:\n",
    "\n",
    "(1) When backward computing value function, suppose that $\\displaystyle V_{k, j}$ is the value function for time $k$ and state $j$, and $\\displaystyle \\theta_{k, j}$ is the strategy for time $k$ and state $j$:\n",
    "\n",
    "- Define gain function $\\displaystyle g_k(\\theta_k, \\Delta \\theta_k) = u(\\theta_k)$, which does not depend on $ \\Delta \\theta_k$\n",
    "\n",
    "- At time $k$ and state $j_0$, define value function $$\\displaystyle \\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) = g_k(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) + \\sum_{j = 1}^{nS} [(V_{k+1, j}(\\theta_{k, j_0} + \\Delta \\theta_{k, j_0})\\text{Pr}(\\text{State } j_0 \\text{ to State } j))] = u(\\theta_{k, j_0}) + \\sum_{j = 1}^{nS}[\\cdots]$$ where $nS$ is the number of state. <br>\n",
    "- This is because different states at time $k + 1$ has different value functions, so we take their mean to compute value function at time $k$. <br>\n",
    "At time $T$, we can set $\\displaystyle V_{T+1, j}(\\theta_{T, j_0} + \\Delta \\theta_{T, j_0}) = 0, \\ \\forall \\, j, j_0$ <br>\n",
    "\n",
    "- Then our objective at time $k$ and state $j_0$ is: $$\\displaystyle \\max_{\\Delta \\theta_{k, j_0}}\\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0})$$<br>\n",
    "\n",
    "- Note that there is no trading costs, so $$V(\\theta_{k, j_0}) = \\displaystyle \\max_{\\Delta \\theta_{k, j_0}}\\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) \\equiv \\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\cdot)$$\n",
    "\n",
    "- Since our objective does not depends on $\\Delta \\theta_{k, j_0}$, subsequently does not depend on $\\theta_{k+1, j}$ and $\\theta_{k-1, j}, \\ \\forall \\, j$.\n",
    "\n",
    "- Hence we can directly choose the optimal $\\displaystyle \\theta_{k, j_0}$ that maximize $\\displaystyle V(\\theta_{k, j_0})$ at time $k$,  $\\displaystyle \\forall \\, k = 1, 2, \\ldots, T$, and these choices form the dynamic optimal strategy. We do not need the forward step to comupte optimal $\\theta$.\n",
    "\n",
    "- All $\\theta_{k, j}$ are represented in dollar unit, so we compute security's price at state $j$ as $p_j$, and set the number of shares in our strategy: $\\displaystyle \\frac{\\theta_{k, j}}{p_j}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4, optimal strategy with no trading costs\n",
    "\n",
    "def dpStrategy(S, trS, T, p, u):\n",
    "    \n",
    "    '''\n",
    "    the program that finds self-financing strategy of maximizing utility expectation with no trading costs\n",
    "    Parameters:\n",
    "       S: the finite state space, suppose the number of state is nS\n",
    "       trS: the transition matrix of the finite state space\n",
    "       T: number of states in this strategy, X1, X2,..., XT\n",
    "       p: the price function of the Markov Chain\n",
    "       u: the investor's utility function \n",
    "    Return: \n",
    "       M: an (nS*T) matrix that represents the optimal strategy at each time Xt, t = 1,2,...T\n",
    "          where the k-th column represents the optimal strategy at each state at Xk\n",
    "    '''\n",
    "    \n",
    "    # given the state space and transition matrix\n",
    "    # compute mean and variance for investment at each state\n",
    "    nS = len(S)\n",
    "    # initialize arrays to record mean and standard deviation\n",
    "    muS = np.zeros(nS)\n",
    "    sigmaS = np.zeros(nS)\n",
    "    for i in range(nS):\n",
    "        nextSprob = trS[i, :]\n",
    "        mu = nextSprob.dot(S.reshape(nS, 1)) # mean\n",
    "        sigma = 0\n",
    "        for j in range(nS):\n",
    "            sigma += nextSprob[0,j] * (S[j] - mu)**2 # variance\n",
    "        muS[i], sigmaS[i] = mu, np.sqrt(sigma) # record mean and standard deviation\n",
    "    \n",
    "    # initialize the matrix of value function\n",
    "    V = np.zeros((nS, T + 1))\n",
    "    # initialize the matrix of result\n",
    "    M = np.zeros((nS, T + 1))\n",
    "    # compute optimal strategy at each time step and each state\n",
    "    # detailed algorithm is showed above\n",
    "    for i in range(T, -1, -1):\n",
    "        for j in range(nS):\n",
    "            # construct the objective function that include utility function and next time's value function\n",
    "            # take the negative so python built-in minimization can be used\n",
    "            if (i == T):\n",
    "                uNeg = lambda x, mu, sigma: -(u(x, mu, sigma)) \n",
    "            else:\n",
    "                # next time's value function contains each state's value function at next time\n",
    "                uNeg = lambda x, mu, sigma: -(u(x, mu, sigma) + V[:, i+1].dot(S.reshape(nS, 1))) \n",
    "            # compute the optimal amount given current state\n",
    "            optimalAmount = spop.minimize(uNeg, 0, (muS[j], sigmaS[j])).x\n",
    "            # compute the current price of the security for self-financing purpose\n",
    "            # and to compute optimal shares\n",
    "            price = p(S[j])\n",
    "            # record the result\n",
    "            M[j][i] = optimalAmount / price\n",
    "            if (i == T):\n",
    "                V[j, i] = u(optimalAmount, muS[j], sigmaS[j])\n",
    "            else:\n",
    "                V[j, i] = u(optimalAmount, muS[j], sigmaS[j]) + V[:, i+1].dot(S.reshape(nS, 1))\n",
    "    return pd.DataFrame(M, columns = ['Time %d' % i for i in range(T + 1)], \n",
    "                        index = ['State %d' % i for i in range(1, nS + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal dynamic strategy(in shares) for example defined above is:\n",
      "\n",
      "            Time 0     Time 1     Time 2     Time 3\n",
      "State 1 -31.559010 -31.559013 -31.559013 -31.559002\n",
      "State 2 -16.672919 -16.672922 -16.672915 -16.672919\n",
      "State 3   7.518796   7.518796   7.518796   7.518796\n",
      "State 4  31.989398  31.989398  31.989398  31.989386\n",
      "State 5  46.457613  46.457613  46.457613  46.457630\n"
     ]
    }
   ],
   "source": [
    "# define the finite state space set in all exapmles\n",
    "# each state represents the PnL per dollar investment\n",
    "S_def = np.array([-0.02, -0.01, 0, 0.015, 0.025])\n",
    "# define a transition matrix for the state space\n",
    "trS_def = np.matrix([[0.35, 0.25, 0.2, 0.15, 0.05], \n",
    "                 [0.3, 0.25, 0.2, 0.15, 0.1], \n",
    "                 [0.2, 0.2, 0.2, 0.2, 0.2], \n",
    "                 [0.1, 0.15, 0.2, 0.25, 0.3], \n",
    "                 [0.05, 0.15, 0.2, 0.25, 0.35]])\n",
    "# define the number of time step in all examples\n",
    "T_def = 3\n",
    "\n",
    "# default investor's utility function, u(x) = mu*x - (sigma*x)^2/2\n",
    "# since this function is equivalent to the expectation of exponential utility\n",
    "# this function is applied to find the optimal strategy in all exapmles\n",
    "u_def = lambda x, mu, sigma: mu * x - (sigma * x)**2 / 2\n",
    "\n",
    "# default price function of the Markov Chain\n",
    "# this function is applied to find the optimal strategy in all exapmles\n",
    "p_def = lambda x: 1 + x\n",
    "\n",
    "# display the result\n",
    "print(\"The optimal dynamic strategy(in shares) for example defined above is:\")\n",
    "print(\"\")\n",
    "print(dpStrategy(S = S_def, trS = trS_def, T = T_def, p = p_def, u = u_def))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of applying the program to find dynamic strategy of the objective $\\displaystyle \\max_{\\theta}\\mathbb{E}[u(W_T^{\\theta})]$ is showed above. \n",
    "\n",
    "In this example, I set the utility function as $\\displaystyle u(x) = \\mu x - \\frac{\\sigma^2 x^2}{2}$.\n",
    "\n",
    "This is because for exponential utility function, if $\\displaystyle v(w) = -e^{-w}$, then $\\displaystyle \\mathbb{E}[v(w)] \\iff \\mu_w w - \\frac{\\sigma_w^2 w^2}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. <br>\n",
    "\n",
    "The program of finding optimal dynamic strategy with Garleanu-Pedersen-type objective is implemented below.\n",
    "\n",
    "The first function is considering linear trading costs, and the second is considering quadratic trading costs.\n",
    "\n",
    "Something that needs to being specified:\n",
    "\n",
    "(1) When backward computing value function, suppose that $\\displaystyle V_{k, j}$ is the value function for time $k$ and state $j$, and $\\displaystyle \\theta_{k, j}$ is the strategy for time $k$ and state $j$:\n",
    "\n",
    "- Define gain function $\\displaystyle g_k(\\theta_k, \\Delta \\theta_k) = \\mu\\theta_k - \\frac{\\sigma^2\\theta_k^2}{2} - \\lambda\\vert\\Delta \\theta_k\\vert$ for linear trading costs. ($\\displaystyle \\frac{\\lambda(\\Delta \\theta_k)^2}{2}$ for quadratic) <br>\n",
    "\n",
    "- At time $k$ and state $j_0$, define value function $$\\displaystyle \\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) = g_k(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) + \\sum_{j = 1}^{nS} [(V_{k+1, j}(\\theta_{k, j_0} + \\Delta \\theta_{k, j_0})\\text{Pr}(\\text{State } j_0 \\text{ to State } j))]$$ where $nS$ is the number of state. <br>\n",
    "- This is because different states at time $k + 1$ has different value functions, so we take their mean to compute value function at time $k$. <br>\n",
    "At time $T$, we can set $\\displaystyle V_{T+1, j}(\\theta_{T, j_0} + \\Delta \\theta_{T, j_0}) = 0, \\ \\forall \\, j, j_0$ <br>\n",
    "\n",
    "- Then our objective at time $k$ and state $j_0$ is: $$\\displaystyle \\max_{\\Delta \\theta_{k, j_0}}\\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0})$$<br>\n",
    "\n",
    "- By taking partial derivatives and set to zero: $\\displaystyle \\partial_{\\Delta \\theta_{k, j_0}}\\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) = 0$, we can have a relationship between $\\theta_{k, j_0}$ and $\\Delta \\theta_{k, j_0}: \\Delta \\theta_{k, j_0} = d_{k, j_0}(\\theta_{k, j_0})$<br>\n",
    "\n",
    "- Replace $\\Delta \\theta_{k, j_0}$ by $d_{k, j_0}(\\theta_{k, j_0})$ in $\\displaystyle \\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0})$, <br> \n",
    "we can have that: $$V_{k, j_0}(\\theta_{k, j_0}) = \\max_{\\Delta \\theta_{k, j_0}}\\bar{V_{k, j_0}}(\\theta_{k, j_0}, \\Delta \\theta_{k, j_0}) = \\bar{V_{k, j_0}}(\\theta_{k, j_0}, d_{k, j_0}(\\theta_{k, j_0}))$$\n",
    "\n",
    "which is a value function only depends on $\\theta_{k, j_0}$.<br>\n",
    "\n",
    "(2) After computing all value functions, $V_{0, j}(\\theta_{0, j}), V_{1, j}(\\theta_{1, j}), \\cdots$, we compute optimal strategy forward recursively.\n",
    "\n",
    "- At time $0$, find $\\theta_{0, j}$ that maximizes $V_{0, j}(\\theta_{0, j}), \\forall \\, j$\n",
    "\n",
    "- At time $k$, we have known the strategy at time $k - 1$ and the relationship between $\\theta_{k-1, j}$ and $\\Delta \\theta_{k-1, j}$: $\\displaystyle \\Delta \\theta_{k-1, j} = d_{k-1, j}(\\theta_{k-1, j}), \\forall \\, j$\n",
    "\n",
    "- Then at time $k$ and state $j_0$: $$\\theta_{k, j_0} = \\sum_{j = 1}^{nS} [(\\theta_{k - 1, j} + d_{k-1, j}(\\theta_{k-1, j}))\\text{Pr}(\\text{State } j \\text{ to State } j_0)]$$ since different states at time $k - 1$ has different optimal strategies, so we take their mean\n",
    "\n",
    "- All $\\theta_{k, j}$ are represented in dollar unit, so we compute security's price at state $j$ as $p_j$, and set the number of shares in our strategy: $\\displaystyle \\frac{\\theta_{k, j}}{p_j}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5(a), optimal strategy with linear trading costs\n",
    "\n",
    "import sympy as sp\n",
    "\n",
    "def dpStrategy_lin(S, trS, T, lbd, p):\n",
    "    \n",
    "    '''\n",
    "    the program that finds self-financing strategy of maximizing Garleanu-Pedersen-type\n",
    "        objective with linear trading costs\n",
    "    Parameters:\n",
    "       S: the finite state space, suppose the number of state is nS\n",
    "       trS: the transition matrix of the finite state space\n",
    "       T: number of states in this strategy, X1, X2,..., XT\n",
    "       lbd: the parameter of linear trading costs\n",
    "       p: the price function of the Markov Chain\n",
    "    Return: \n",
    "       M: an (nS*T) matrix that represents the optimal strategy at each time Xt, t = 1,2,...T\n",
    "          where the k-th column represents the optimal strategy at each state at Xk\n",
    "    '''\n",
    "    # given the state space and transition matrix\n",
    "    # compute mean and variance for investment at each state\n",
    "    nS = len(S)\n",
    "    # initialize arrays to record mean and standard deviation\n",
    "    muS = np.zeros(nS)\n",
    "    sigmaS = np.zeros(nS)\n",
    "    for i in range(nS):\n",
    "        nextSprob = trS[i, :]\n",
    "        mu = nextSprob.dot(S.reshape(nS, 1)) # mean\n",
    "        sigma = 0\n",
    "        for j in range(nS):\n",
    "            sigma += nextSprob[0,j] * (S[j] - mu)**2 # variance\n",
    "        muS[i], sigmaS[i] = mu, np.sqrt(sigma) # record mean and standard deviation\n",
    "        \n",
    "    # initialize the matrix of value function\n",
    "    V = [[0] * (T + 1) for i in range(nS)]\n",
    "    # initialize the matrix to store the relationship between theta_k and (delta theta_k) for k = 0, ..., T \n",
    "    rel = [[0] * (T + 1) for i in range(nS)]\n",
    "    # detailed algorithm for finding value function and relationship can be found above\n",
    "    for i in range(T, -1, -1):\n",
    "        for j in range(nS):\n",
    "            # update GPtype objective function for time Ti by value function of T_(i + 1)\n",
    "            x, y = sp.symbols('x,y',real=True)\n",
    "            if (i == T):\n",
    "                # construct V_hat(theta, (delta theta))\n",
    "                obj_ori = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*y\n",
    "                for k in range(nS):\n",
    "                    obj_ori += (muS[k]*(x+y) - (sigmaS[k]*(x+y))**2/2) * trS[j, k]\n",
    "                # find relationship between theta and (delta theta))\n",
    "                obj_rel = sp.solve(obj_ori.diff(y), y)\n",
    "                # record the result\n",
    "                rel[j][i] = obj_rel[0]\n",
    "                # construct V(theta) by V_hat(theta, (delta theta)) and relationship between theta and (delta theta))\n",
    "                obj_new = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*(obj_rel[0])\n",
    "                for k in range(nS):\n",
    "                    obj_new += (muS[k]*(x+obj_rel[0]) - (sigmaS[k]*(x+obj_rel[0]))**2/2) * trS[j, k]\n",
    "                # record the result\n",
    "                V[j][i] = obj_new\n",
    "            else:\n",
    "                # construct V_hat(theta, (delta theta))\n",
    "                obj_ori = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*y\n",
    "                for k in range(nS):\n",
    "                    obj_ori += V[k][i+1].replace(x, x+y) * trS[j, k]\n",
    "                # find relationship between theta and (delta theta))\n",
    "                obj_rel = sp.solve(obj_ori.diff(y), y)\n",
    "                # record the result\n",
    "                rel[j][i] = obj_rel[0]\n",
    "                # construct V(theta) by V_hat(theta, (delta theta)) and relationship between theta and (delta theta))\n",
    "                obj_new = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*(obj_rel[0])\n",
    "                for k in range(nS):\n",
    "                    obj_new += V[k][i+1].replace(x, x+obj_rel[0]) * trS[j, k]\n",
    "                # record the result\n",
    "                V[j][i] = obj_new\n",
    "\n",
    "    # initialize the matrix of result\n",
    "    M = np.zeros((nS, T + 1))\n",
    "    # detailed algorithm for optimal strategy can be found above\n",
    "    for i in range(T + 1):\n",
    "        for j in range(nS):\n",
    "            if (i == 0):\n",
    "                # compute the current price of the security for self-financing purpose\n",
    "                # and to compute optimal shares\n",
    "                price = p(S[j])\n",
    "                # compute optimal strategy at time 0\n",
    "                # take the negative of value function so python built-in minimization can be used\n",
    "                M[j, i] = spop.minimize(lambda xs: -sp.lambdify(x, V[j][i])(xs), 0).x / price \n",
    "            else:\n",
    "                price = p(S[j])\n",
    "                # compute optimal strategy at time k given optimal strategy at time (k - 1)\n",
    "                sum = 0\n",
    "                for k in range(nS):\n",
    "                    sum += (M[k, i - 1] + sp.lambdify(x, V[k][i - 1])(M[k, i - 1])) * trS[j, k]\n",
    "                M[j, i] = (sum / price)\n",
    "\n",
    "    return pd.DataFrame(M, columns = ['Time %d' % i for i in range(T + 1)], \n",
    "                        index = ['State %d' % i for i in range(1, nS + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5(b), optimal strategy with quadratic trading costs\n",
    "\n",
    "def dpStrategy_quad(S, trS, T, lbd, p):\n",
    "    \n",
    "    '''\n",
    "    the program that finds self-financing strategy of maximizing Garleanu-Pedersen-type\n",
    "        objective with quadratic trading costs\n",
    "    Parameters:\n",
    "       S: the finite state space, suppose the number of state is nS\n",
    "       trS: the transition matrix of the finite state space\n",
    "       T: number of states in this strategy, X1, X2,..., XT\n",
    "       lbd: the parameter of quadratic trading costs\n",
    "       p: the price function of the Markov Chain\n",
    "    Return: \n",
    "       M: an (nS*T) matrix that represents the optimal strategy at each time Xt, t = 1,2,...T\n",
    "          where the k-th column represents the optimal strategy at each state at Xk\n",
    "    '''\n",
    "    # given the state space and transition matrix\n",
    "    # compute mean and variance for investment at each state\n",
    "    nS = len(S)\n",
    "    # initialize arrays to record mean and standard deviation\n",
    "    muS = np.zeros(nS)\n",
    "    sigmaS = np.zeros(nS)\n",
    "    for i in range(nS):\n",
    "        nextSprob = trS[i, :]\n",
    "        mu = nextSprob.dot(S.reshape(nS, 1)) # mean\n",
    "        sigma = 0\n",
    "        for j in range(nS):\n",
    "            sigma += nextSprob[0,j] * (S[j] - mu)**2 # variance\n",
    "        muS[i], sigmaS[i] = mu, np.sqrt(sigma) # record mean and standard deviation\n",
    "        \n",
    "    # initialize the matrix of value function\n",
    "    V = [[0] * (T + 1) for i in range(nS)]\n",
    "    # initialize the matrix to store the relationship between theta_k and (delta theta_k) for k = 0, ..., T \n",
    "    rel = [[0] * (T + 1) for i in range(nS)]\n",
    "    # detailed algorithm for finding value function and relationship can be found above\n",
    "    for i in range(T, -1, -1):\n",
    "        for j in range(nS):\n",
    "            # update GPtype objective function for time Ti by value function of T_(i + 1)\n",
    "            x, y = sp.symbols('x,y',real=True)\n",
    "            if (i == T):\n",
    "                # construct V_hat(theta, (delta theta))\n",
    "                obj_ori = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*y**2/2\n",
    "                for k in range(nS):\n",
    "                    obj_ori += (muS[k]*(x+y) - (sigmaS[k]*(x+y))**2/2) * trS[j, k]\n",
    "                # find relationship between theta and (delta theta))\n",
    "                obj_rel = sp.solve(obj_ori.diff(y), y)\n",
    "                # record the result\n",
    "                rel[j][i] = obj_rel[0]\n",
    "                # construct V(theta) by V_hat(theta, (delta theta)) and relationship between theta and (delta theta))\n",
    "                obj_new = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*(obj_rel[0])**2/2\n",
    "                for k in range(nS):\n",
    "                    obj_new += (muS[k]*(x+obj_rel[0]) - (sigmaS[k]*(x+obj_rel[0]))**2/2) * trS[j, k]\n",
    "                # record the result\n",
    "                V[j][i] = obj_new\n",
    "            else:\n",
    "                # construct V_hat(theta, (delta theta))\n",
    "                obj_ori = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*y**2/2\n",
    "                for k in range(nS):\n",
    "                    obj_ori += V[k][i+1].replace(x, x+y) * trS[j, k]\n",
    "                # find relationship between theta and (delta theta))\n",
    "                obj_rel = sp.solve(obj_ori.diff(y), y)\n",
    "                # record the result\n",
    "                rel[j][i] = obj_rel[0]\n",
    "                # construct V(theta) by V_hat(theta, (delta theta)) and relationship between theta and (delta theta))\n",
    "                obj_new = muS[j] * x - (sigmaS[j] * x)**2 / 2 - lbd*(obj_rel[0])**2/2\n",
    "                for k in range(nS):\n",
    "                    obj_new += V[k][i+1].replace(x, x+obj_rel[0]) * trS[j, k]\n",
    "                # record the result\n",
    "                V[j][i] = obj_new\n",
    "\n",
    "    # initialize the matrix of result\n",
    "    M = np.zeros((nS, T + 1))\n",
    "    # detailed algorithm for optimal strategy can be found above\n",
    "    for i in range(T + 1):\n",
    "        for j in range(nS):\n",
    "            if (i == 0):\n",
    "                # compute the current price of the security for self-financing purpose\n",
    "                # and to compute optimal shares\n",
    "                price = p(S[j])\n",
    "                # compute optimal strategy at time 0\n",
    "                # take the negative of value function so python built-in minimization can be used\n",
    "                M[j, i] = spop.minimize(lambda xs: -sp.lambdify(x, V[j][i])(xs), 0).x / price \n",
    "            else:\n",
    "                price = p(S[j])\n",
    "                # compute optimal strategy at time k given optimal strategy at time (k - 1)\n",
    "                sum = 0\n",
    "                for k in range(nS):\n",
    "                    sum += (M[k, i - 1] + sp.lambdify(x, V[k][i - 1])(M[k, i - 1])) * trS[j, k]\n",
    "                M[j, i] = (sum / price)\n",
    "\n",
    "    return pd.DataFrame(M, columns = ['Time %d' % i for i in range(T + 1)], \n",
    "                        index = ['State %d' % i for i in range(1, nS + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal dynamic strategy(in shares) considering linear trading costs is:\n",
      "\n",
      "            Time 0     Time 1     Time 2     Time 3\n",
      "State 1  -5.259833  16.702092  25.637264  29.027332\n",
      "State 2   5.557649  20.349195  26.719865  29.191068\n",
      "State 3  26.315805  30.074074  30.081199  30.146273\n",
      "State 4  52.627676  39.411277  33.211558  30.929446\n",
      "State 5  69.686388  42.712291  34.183296  31.069034\n",
      "\n",
      "\n",
      "The optimal dynamic strategy(in shares) considering quadratic trading costs is:\n",
      "\n",
      "            Time 0     Time 1    Time 2    Time 3\n",
      "State 1  -2.477055   4.604484  7.284988  8.288116\n",
      "State 2   0.747211   5.688636  7.620971  8.348112\n",
      "State 3   8.512394   8.661306  8.654959  8.656687\n",
      "State 4  16.405064  11.518091  9.620844  8.915017\n",
      "State 5  19.684974  12.497773  9.922566  8.966848\n"
     ]
    }
   ],
   "source": [
    "# display the result for linear trading costs\n",
    "print(\"The optimal dynamic strategy(in shares) considering linear trading costs is:\")\n",
    "print(\"\")\n",
    "print(dpStrategy_lin(S = S_def, trS = trS_def, T = T_def, lbd = 0.005, p = p_def))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# display the result for quadratic trading costs\n",
    "print(\"The optimal dynamic strategy(in shares) considering quadratic trading costs is:\")\n",
    "print(\"\")\n",
    "print(dpStrategy_quad(S = S_def, trS = trS_def, T = T_def, lbd = 1, p = p_def))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example of applying the program to find optimal dynamic strategy of Garleanu-Pedersen-type objective, with linear and quadratic trading costs respectively, is showed above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
